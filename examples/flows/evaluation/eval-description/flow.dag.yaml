id: template_eval_flow
name: Template Evaluation Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  image:
    type: image
    default: data/img2.jpg
  qustion:
    type: string
    default: What's in the image?
  answer:
    type: string
    default: A yellow bird
outputs:
  results:
    type: string
    reference: ${evaluate_description_matchness.output}
nodes:
- name: evaluate_description_matchness
  type: custom_llm
  source:
    type: package_with_prompt
    tool: promptflow.tools.openai_gpt4v.OpenAI.chat
    path: evaluate_description_matchness.jinja2
  inputs:
    connection: openai-connection
    model: gpt-4-vision-preview
    max_tokens: 200
    image_input: ${inputs.image}
    question: ${inputs.qustion}
    answer: ${inputs.answer}
- name: aggregate
  type: python
  source:
    type: code
    path: aggregate.py
  inputs:
    grades: ${evaluate_description_matchness.output}
  aggregation: true
